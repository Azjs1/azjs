# predict_lstm_signal.py (Ù†Ø³Ø®Ø© Ù…Ø­Ø³Ù‘Ù†Ø©)

import os
import numpy as np
import pandas as pd
import logging
import joblib
from tensorflow.keras.models import load_model
from binance.client import Client
from datetime import datetime

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø³Ø¬Ù„Ø§Øª
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# Ø¥Ø¹Ø¯Ø§Ø¯ Binance API
API_KEY = os.getenv("BINANCE_API_KEY")
API_SECRET = os.getenv("BINANCE_API_SECRET")
client = Client(API_KEY, API_SECRET)

# Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ù„Ù…Ø­ÙˆÙ„Ø§Øª
MODEL_PATH = "models/lstm_model.h5"
SCALER_PATH = "models/lstm_scaler.pkl"
LOOK_BACK = 50
INTERVALS = ["5m", "15m", "1h", "4h"]

# âœ… Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­ÙŠØ© Ù…Ù† Binance ÙˆØ¯Ù…Ø¬Ù‡Ø§ Ø¹Ø¨Ø± Ø§Ù„ÙØ±ÙŠÙ…Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ©
def fetch_recent_data(symbol="BTCUSDT"):
    try:
        def fetch(symbol, interval):
            klines = client.get_klines(symbol=symbol, interval=interval, limit=100)
            df = pd.DataFrame(klines, columns=[
                "timestamp", "open", "high", "low", "close", "volume",
                "close_time", "qav", "trades", "tbbav", "tbqav", "ignore"
            ])
            df["timestamp"] = pd.to_datetime(df["timestamp"], unit="ms")
            df.set_index("timestamp", inplace=True)
            df = df[["close"]].astype(float)
            df.columns = [f"close_{interval}"]
            return df

        final_df = None
        for interval in INTERVALS:
            df = fetch(symbol, interval)
            if final_df is None:
                final_df = df
            else:
                final_df = final_df.join(df, how="outer")

        final_df["avg_close"] = final_df.mean(axis=1)
        final_df.dropna(inplace=True)
        return final_df

    except Exception as e:
        logging.error(f"âŒ [Data Fetch Error] ÙØ´Ù„ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Binance: {e}")
        return pd.DataFrame()

# âœ… ØªÙˆÙ‚Ø¹ Ø¥Ø´Ø§Ø±Ø© LSTM Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ø§Ù„ÙŠØ©
def predict_lstm_signal():
    try:
        if not os.path.exists(MODEL_PATH) or not os.path.exists(SCALER_PATH):
            logging.warning("âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„ÙØ§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø£Ùˆ Ø§Ù„Ù…Ø­ÙˆÙ„.")
            return {
                "signal": 0,
                "confidence": 0.5,
                "prediction": 0.5,
                "timestamp": None,
                "volatility": 0.0
            }

        model = load_model(MODEL_PATH)
        scaler = joblib.load(SCALER_PATH)
        df = fetch_recent_data()

        if df.empty or len(df) < LOOK_BACK:
            logging.warning("âš ï¸ Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ÙƒØ§ÙÙŠØ© Ù„Ø¥Ø´Ø§Ø±Ø© LSTM.")
            return {
                "signal": 0,
                "confidence": 0.5,
                "prediction": 0.5,
                "timestamp": None,
                "volatility": 0.0
            }

        data = df[["avg_close"]].values
        data_scaled = scaler.transform(data)
        last_seq = data_scaled[-LOOK_BACK:]
        X = np.reshape(last_seq, (1, LOOK_BACK, 1))

        prediction = model.predict(X)[0][0]
        signal = 1 if prediction > 0.5 else 0
        confidence = float(prediction)
        volatility = float(np.std(df["avg_close"].pct_change().dropna()))

        logging.info(f"ğŸ“ˆ Ø¥Ø´Ø§Ø±Ø© LSTM: {signal} | Ø§Ù„Ø«Ù‚Ø©: {confidence:.4f} | Ø§Ù„ØªØ°Ø¨Ø°Ø¨: {volatility:.4f}")

        return {
            "signal": signal,
            "confidence": confidence,
            "prediction": prediction,
            "timestamp": df.index[-1],
            "volatility": volatility
        }

    except Exception as e:
        logging.error(f"âŒ [LSTM Prediction Error] {e}")
        return {
            "signal": 0,
            "confidence": 0.5,
            "prediction": 0.5,
            "timestamp": None,
            "volatility": 0.0
        }